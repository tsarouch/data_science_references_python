1) create a new pyspark notebook profile
> ipython profile create pysparknb

2) edit the created profile
> emacs ~/.ipython/profile_pysparknb/ipython_notebook_config.py 
"====="
c = get_config()
c.NotebookApp.ip = '*'
c.NotebookApp.open_browser = False
c.NotebookApp.port = 8881 # chose a random own one
"======"

3) Navigate to the folder you are interested to run the pyspark and run:
IPYTHON_OPTS="notebook --profile=pysparknb" /Users/charil.../bin/pyspark  
--jars /Users/charil.../spark-examples-1.3.1-hadoop2.4.0.jar
--master local[2]



