{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This is done at a time where Spark did not support csv parsing 'in single line'\n",
    "I m sure it will come soon...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" === e.g. the csv file looks like this:===\n",
    "field1, field2, time\n",
    "5768, 49.4,'2014-12-19 04:15:00+01',\n",
    "1039, 26.1, 2014-12-18 14:45:00+01'\n",
    "...\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Notebook with pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPYTHON_OPTS=\"notebook --profile=pysparknb\" /Users/charil/.../bin/pyspark  --jars /Users/chari.../spark-examples-1.3.1-hadoop2.4.0.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the csv data\n",
    "data = sc.textFile('tableau_grid_tile_refactored.csv')\n",
    "\n",
    "# remove the header\n",
    "header = data.take(1)[0]\n",
    "rows = data.filter(lambda line: line != header)\n",
    "\n",
    "# parse the lines, split with delimiter and provide Row names (and types if you wish, if not inferred)\n",
    "row_parts = rows.map(lambda l: l.split(\"|\"))\n",
    "data_rdd = row_parts.map(lambda p: Row(area_id=p[0], cnt=p[1],  start_time=str(p[2])))\n",
    "\n",
    "# convert to dataframe\n",
    "df = sqlContext.createDataFrame(data_rdd)\n",
    "\n",
    "# lets see now 2 rows of it\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "field1 field2     start_time          \n",
    "5768   49.64 2014-12-19 04:15:...\n",
    "1039   266.1 2014-12-18 14:45:..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
